% Encoding: UTF-8

@Article{Li17,
  author         = {Yuxi Li},
  title          = {Deep Reinforcement Learning: An Overview},
  year           = {2017},
  month          = jan,
  abstract       = {We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions.},
  eprint         = {1701.07274},
  oai2identifier = {1701.07274},
  owner          = {andi},
  timestamp      = {2018.03.26},
}

@InProceedings{NHR99,
  author    = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart J.},
  title     = {Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
  booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
  year      = {1999},
  series    = {ICML '99},
  pages     = {278--287},
  address   = {San Francisco, CA, USA},
  publisher = {Morgan Kaufmann Publishers Inc.},
  acmid     = {657613},
  isbn      = {1-55860-612-2},
  numpages  = {10},
  url       = {http://dl.acm.org/citation.cfm?id=645528.657613},
}

@Article{PS08,
  author    = {Jan Peters and Stefan Schaal},
  title     = {Reinforcement learning of motor skills with policy gradients},
  journal   = {Neural Networks},
  year      = {2008},
  volume    = {21},
  number    = {4},
  pages     = {682 - 697},
  issn      = {0893-6080},
  note      = {Robotics and Neuroscience},
  doi       = {https://doi.org/10.1016/j.neunet.2008.02.003},
  keywords  = {Reinforcement learning, Policy gradient methods, Natural gradients, Natural Actor-Critic, Motor skills, Motor primitives},
  owner     = {andi},
  timestamp = {2018.03.26},
  url       = {http://www.sciencedirect.com/science/article/pii/S0893608008000701},
}

@InProceedings{Kak02,
  author    = {Kakade, Sham M},
  title     = {A natural policy gradient},
  booktitle = {Advances in neural information processing systems},
  year      = {2002},
  pages     = {1531--1538},
  owner     = {andi},
  timestamp = {2018.03.27},
}

@Article{KBP13,
  author    = {Jens Kober and J. Andrew Bagnell and Jan Peters},
  title     = {Reinforcement learning in robotics: A survey},
  journal   = {The International Journal of Robotics Research},
  year      = {2013},
  volume    = {32},
  number    = {11},
  pages     = {1238-1274},
  abstract  = { Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and model-free as well as between value-function-based and policy-search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research. },
  doi       = {10.1177/0278364913495721},
  eprint    = {https://doi.org/10.1177/0278364913495721},
  owner     = {andi},
  timestamp = {2018.03.26},
  url       = {https://doi.org/10.1177/0278364913495721},
}

@Article{MBM+16,
  author       = {Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  title        = {Asynchronous Methods for Deep Reinforcement Learning},
  abstract     = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
  date         = {2016-02-04},
  eprint       = {1602.01783v2},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  file         = {online:http\://arxiv.org/pdf/1602.01783v2:PDF},
  journaltitle = {ICML 2016},
  keywords     = {cs.LG},
  owner        = {andi},
  timestamp    = {2018.03.28},
}

@Article{DCH+16,
  author      = {Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel},
  title       = {Benchmarking Deep Reinforcement Learning for Continuous Control},
  abstract    = {Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github.com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers.},
  date        = {2016-04-22},
  eprint      = {1604.06778v3},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1604.06778v3:PDF},
  keywords    = {cs.LG, cs.AI, cs.RO},
  owner       = {andi},
  timestamp   = {2018.04.02},
}

@InProceedings{NB15,
  author    = {T. D. Nguyen and J. Burgner-Kahrs},
  title     = {A tendon-driven continuum robot with extensible sections},
  booktitle = {Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS)},
  year      = {2015},
  pages     = {2130--2135},
  month     = sep,
  doi       = {10.1109/IROS.2015.7353661},
  keywords  = {design engineering, discs (structures), manipulators, permanent magnets, 3D space, alternating pole orientation, equidistant disk spacing, extensible sections, fixed section lengths, follow-the-leader fashion, linear translation, magnetic repulsion forces, permanent magnets, rigid link serial manipulators, spacer disks, telescoping backbone, tendon actuation, tendon-driven continuum robot, tendon-driven robot designs, tortuous paths, Electron tubes, Manipulators, Neodymium, Pneumatic systems, Prototypes, Tendons},
  owner     = {andi},
  timestamp = {2018.04.03},
}

@Article{WIJ10,
  author    = {Webster III, Robert J and Jones, Bryan A},
  title     = {Design and kinematic modeling of constant curvature continuum robots: A review},
  journal   = {The International Journal of Robotics Research},
  year      = {2010},
  volume    = {29},
  number    = {13},
  pages     = {1661--1683},
  owner     = {andi},
  publisher = {SAGE Publications Sage UK: London, England},
  timestamp = {2018.04.04},
}

@Article{JW06,
  author    = {B. A. Jones and I. D. Walker},
  title     = {Kinematics for multisection continuum robots},
  journal   = IEEE_J_RO,
  year      = {2006},
  volume    = {22},
  number    = {1},
  pages     = {43--55},
  month     = feb,
  issn      = {1552-3098},
  doi       = {10.1109/TRO.2005.861458},
  keywords  = {manipulator kinematics, shape control, actuator inputs, continuous backbone robots, multisection continuum robot kinematics, physical manipulator constraints, pneumatic pressures, robot shape coordinates, shape control, spatial multisection continuum manipulators, tendon lengths, workspace Cartesian coordinates, Hardware, Legged locomotion, Manipulators, Medical robotics, Pneumatic actuators, Robot kinematics, Robot sensing systems, Shape control, Spine, Tendons, Biologically inspired robots, continuum robot, kinematics, tentacle, trunk},
  owner     = {andi},
  timestamp = {2018.04.04},
}

@Article{JW06a,
  author    = {B. A. Jones and I. D. Walker},
  title     = {Practical Kinematics for Real-Time Implementation of Continuum Robots},
  journal   = IEEE_J_RO,
  year      = {2006},
  volume    = {22},
  number    = {6},
  pages     = {1087--1099},
  month     = dec,
  issn      = {1552-3098},
  doi       = {10.1109/TRO.2006.886268},
  keywords  = {manipulator kinematics, continuum manipulators, finite actuation mechanisms, multisection tendon-actuated continuum robots, practical kinematics, Actuators, Arm, Hardware, Joints, Kinematics, Legged locomotion, Manipulators, Orbital robotics, Robot control, Shape, Biologically inspired robots, continuum robot, kinematics, tentacle, trunk},
  owner     = {andi},
  timestamp = {2018.04.04},
}

@Article{CCS09,
  author    = {D. B. Camarillo and C. R. Carlson and J. K. Salisbury},
  title     = {Configuration Tracking for Continuum Manipulators With Coupled Tendon Drive},
  journal   = IEEE_J_RO,
  year      = {2009},
  volume    = {25},
  number    = {4},
  pages     = {798--808},
  month     = aug,
  issn      = {1552-3098},
  doi       = {10.1109/TRO.2009.2022426},
  keywords  = {biological tissues, catheters, flexible manipulators, manipulator kinematics, medical robotics, cardiac catheter, configuration tracking, continuum manipulator, coupled tendon drive, decoupled inverse kinematics, flexible device, forward kinematics, geometrical coupling, linear beam configuration, mechanical coupling, medical procedure, robotic control, shape configuration, tendon displacement, Cable drive, continuum robot, flexible arm, medical robot},
  owner     = {andi},
  timestamp = {2018.04.04},
}

@InCollection{Mat94,
  author    = {Mataric, Maja J},
  title     = {Reward functions for accelerated learning},
  booktitle = {Machine Learning Proceedings 1994},
  publisher = {Elsevier},
  year      = {1994},
  pages     = {181--189},
  owner     = {andi},
  timestamp = {2018.04.23},
}

@InProceedings{SLH+14,
  author    = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  title     = {Deterministic policy gradient algorithms},
  booktitle = {ICML},
  year      = {2014},
  owner     = {andi},
  timestamp = {2018.04.30},
}

@Article{SML+15,
  author    = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  title     = {High-dimensional continuous control using generalized advantage estimation},
  journal   = {arXiv preprint arXiv:1506.02438},
  year      = {2015},
  owner     = {andi},
  timestamp = {2018.05.15},
}

@Article{GSS+17,
  author      = {Aditya Gudimella and Ross Story and Matineh Shaker and Ruofan Kong and Matthew Brown and Victor Shnayder and Marcos Campos},
  title       = {Deep Reinforcement Learning for Dexterous Manipulation with Concept Networks},
  abstract    = {Deep reinforcement learning yields great results for a large array of problems, but models are generally retrained anew for each new problem to be solved. Prior learning and knowledge are difficult to incorporate when training new models, requiring increasingly longer training as problems become more complex. This is especially problematic for problems with sparse rewards. We provide a solution to these problems by introducing Concept Network Reinforcement Learning (CNRL), a framework which allows us to decompose problems using a multi-level hierarchy. Concepts in a concept network are reusable, and flexible enough to encapsulate feature extractors, skills, or other concept networks. With this hierarchical learning approach, deep reinforcement learning can be used to solve complex tasks in a modular way, through problem decomposition. We demonstrate the strength of CNRL by training a model to grasp a rectangular prism and precisely stack it on top of a cube using a gripper on a Kinova JACO arm, simulated in MuJoCo. Our experiments show that our use of hierarchy results in a 45x reduction in environment interactions compared to the state-of-the-art on this task.},
  date        = {2017-09-20},
  eprint      = {1709.06977v1},
  eprintclass = {cs.AI},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1709.06977v1:PDF},
  keywords    = {cs.AI, cs.RO},
  owner       = {andi},
  timestamp   = {2018.06.04},
}

@Article{NCJW09,
  author    = {Srinivas Neppalli and Matthew A. Csencsits and Bryan A. Jones and Ian D. Walker},
  title     = {Closed-Form Inverse Kinematics for Continuum Manipulators},
  year      = {2009},
  volume    = {23},
  pages     = {2077-2091},
  issn      = {0169-1864},
  doi       = {10.1163/016918609x12529299964101},
  owner     = {andi},
  timestamp = {2018.06.04},
}

@Article{HW03,
  author    = {Hannan, Michael W and Walker, Ian D},
  title     = {Kinematics and the implementation of an elephant's trunk manipulator and other continuum style robots},
  journal   = {Journal of robotic systems},
  year      = {2003},
  volume    = {20},
  number    = {2},
  pages     = {45--63},
  owner     = {andi},
  publisher = {Wiley Online Library},
  timestamp = {2018.07.26},
}

@InProceedings{STF04,
  author    = {N. Simaan and R. Taylor and P. Flint},
  title     = {A dexterous system for laryngeal surgery},
  booktitle = {Proc. IEEE Int. Conf. Robotics and Automation ICRA '04},
  year      = {2004},
  volume    = {1},
  pages     = {351--357 Vol.1},
  month     = apr,
  doi       = {10.1109/ROBOT.2004.1307175},
  issn      = {1050-4729},
  keywords  = {dexterous manipulators, manipulator kinematics, medical robotics, patient treatment, position control, detachable milli parallel manipulator, dexterous system, laryngeal surgery, manipulator kinematics, multibackbone snakelike mechanism, soft-tissue manipulation, surgical tool manipulation, throat surgery, Kinematics, Medical robotics, Minimally invasive surgery, Mouth, Prototypes, Robots, Scalability, Spine, Surgical instruments, Wrist},
  owner     = {andi},
  timestamp = {2018.07.26},
}

@Article{RJWRC09,
  author    = {R. J. Webster III and J. M. Romano and N. J. Cowan},
  title     = {Mechanics of Precurved-Tube Continuum Robots},
  journal   = IEEE_J_RO,
  year      = {2009},
  volume    = {25},
  number    = {1},
  pages     = {67--78},
  month     = feb,
  issn      = {1552-3098},
  doi       = {10.1109/TRO.2008.2006868},
  keywords  = {bifurcation, dexterous manipulators, flexible manipulators, medical robotics, pipes, active cannulas, dexterous continuum robots, elastic tube interaction, energy bifurcation, mechanics, medical applications, precurved superelastic tubes, precurved-tube continuum robots, telescoping superelastic tubes, Continuum robot, flexible manipulator, medical robot, snake-like robot},
  owner     = {andi},
  timestamp = {2018.07.26},
}

@Article{DLIB10,
  author    = {P. E. Dupont and J. Lock and B. Itkowitz and E. Butler},
  title     = {Design and Control of Concentric-Tube Robots},
  journal   = IEEE_J_RO,
  year      = {2010},
  volume    = {26},
  number    = {2},
  pages     = {209--225},
  month     = apr,
  issn      = {1552-3098},
  doi       = {10.1109/TRO.2009.2035740},
  keywords  = {bending, flexible manipulators, manipulator kinematics, medical robotics, position control, telerobotics, torsion, actuators, concentric-tube robots, flexible arms, kinematics, medical robots, minimally invasive medical procedures, position control, precurved elastic tubes, telerobotics, torsion, tube bending, Continuum robots, flexible arms, kinematics, medical robots and systems, telerobotics},
  owner     = {andi},
  timestamp = {2018.07.26},
}

@InProceedings{NCJW08,
  author    = {S. Neppalli and M. A. Csencsits and B. A. Jones and I. Walker},
  title     = {A geometrical approach to inverse kinematics for continuum manipulators},
  booktitle = {Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems},
  year      = {2008},
  pages     = {3565--3570},
  month     = sep,
  doi       = {10.1109/IROS.2008.4651125},
  issn      = {2153-0858},
  keywords  = {manipulator kinematics, continuous backbone robot manipulators, continuum manipulators, geometrical approach, inverse kinematics, Algorithm design and analysis, Joints, Kinematics, Manipulators, Robot kinematics, Robots, Three dimensional displays},
  owner     = {andi},
  timestamp = {2018.07.26},
}

@InProceedings{WH99,
  author    = {I. D. Walker and M. W. Hannan},
  title     = {A novel 'elephant's trunk' robot},
  booktitle = {Proc. IEEE/ASME Int. Conf. Advanced Intelligent Mechatronics (Cat. No.99TH8399)},
  year      = {1999},
  pages     = {410--415},
  month     = sep,
  doi       = {10.1109/AIM.1999.803204},
  keywords  = {position control, redundant manipulators, elephant's trunk robot, grasping, hyperredundant robot manipulator, manipulation, segmented backbone, tendons, Arm, End effectors, Humans, Kinematics, Legged locomotion, Manipulators, Robot sensing systems, Shape, Spine, Tendons},
  owner     = {andi},
  timestamp = {2018.07.26},
}

@InCollection{COW08,
  author    = {Chiaverini, Stefano and Oriolo, Giuseppe and Walker, Ian D},
  title     = {Kinematically redundant manipulators},
  booktitle = {Springer handbook of robotics},
  publisher = {Springer},
  year      = {2008},
  pages     = {245--268},
  owner     = {andi},
  timestamp = {2018.07.26},
}

@Article{HY09,
  author    = {S. Hirose and H. Yamada},
  title     = {Snake-like robots [Tutorial]},
  journal   = {IEEE Robotics Automation Magazine},
  year      = {2009},
  volume    = {16},
  number    = {1},
  pages     = {88--98},
  month     = mar,
  issn      = {1070-9932},
  doi       = {10.1109/MRA.2009.932130},
  keywords  = {biomechanics, mobile robots, robot kinematics, Koryu, biomechanical research, muscular force, nuclear reactor related facility, snake locomotion, snake-like active endoscope, snake-like inspection robot, snake-like robots, thrusting force, Kinematics, Motion analysis, Performance analysis, Robotics and automation, Robots, Torque, Tutorials, Biologically inspired robot, snake-like robot, mechanical design},
  owner     = {andi},
  timestamp = {2018.07.26},
}

@Article{BRC15,
  author    = {J. Burgner-Kahrs and D. C. Rucker and H. Choset},
  title     = {Continuum Robots for Medical Applications: A Survey},
  journal   = IEEE_J_RO,
  year      = {2015},
  volume    = {31},
  number    = {6},
  pages     = {1261--1280},
  month     = dec,
  issn      = {1552-3098},
  doi       = {10.1109/TRO.2015.2489500},
  keywords  = {manipulators, medical robotics, surgery, continuum robot manipulator, curvilinear path, medical robotic, rigid-link robot, robotics science, surgical robot, Manipulators, Medical robotics, Robot kinematics, Robot sensing systems, Surgery, Continuous robot manipulator, continuum robot, hyper-redundant robot, robot-assisted surgery, soft robotics, surgical robotics},
  owner     = {andi},
  timestamp = {2018.07.27},
}

@InProceedings{RD99,
  author    = {G. Robinson and J. B. C. Davies},
  title     = {Continuum robots - a state of the art},
  booktitle = {Proc. IEEE Int. Conf. Robotics and Automation (Cat. No.99CH36288C)},
  year      = {1999},
  volume    = {4},
  pages     = {2849--2854 vol.4},
  doi       = {10.1109/ROBOT.1999.774029},
  issn      = {1050-4729},
  keywords  = {mobile robots, motion control, robot dynamics, bending, continuous arcs producing motion, continuum robot, locomotion, mobile robots, serpentine robot, Actuators, Animal structures, Animation, Bellows, Chemical engineering, Humanoid robots, Humans, Industrial relations, Robot motion, Service robots},
  owner     = {andi},
  timestamp = {2018.07.27},
}

@Article{Wal13,
  author    = {Walker, Ian D},
  title     = {Continuous backbone “continuum” robot manipulators},
  journal   = {Isrn robotics},
  year      = {2013},
  volume    = {2013},
  owner     = {andi},
  publisher = {Hindawi Publishing Corporation},
  timestamp = {2018.07.27},
}

@Article{BRG+14,
  author    = {J. Burgner and D. C. Rucker and H. B. Gilbert and P. J. Swaney and P. T. Russell and K. D. Weaver and R. J. Webster},
  title     = {A Telerobotic System for Transnasal Surgery},
  journal   = IEEE_J_MECH,
  year      = {2014},
  volume    = {19},
  number    = {3},
  pages     = {996--1006},
  month     = jun,
  issn      = {1083-4435},
  doi       = {10.1109/TMECH.2013.2265804},
  keywords  = {dexterous manipulators, medical robotics, surgery, telerobotics, cadaver reachability study, concentric tube continuum robots, concentric tube manipulators, endonasal skull base surgery, endonasal surgical robot, expert users, image guidance, laparoscopic training task, mechanics-based models, medical motivation, model-based design, novice users, phantom tumor resection, real-world clinical scenarios, teleoperation methods, telerobotic system, tentacle-like dexterity, transnasal surgery, Active cannula, concentric tube robot, continuum robot, endonasal surgery, minimally-invasive surgery, robot-assisted surgery, teleoperation},
  owner     = {andi},
  timestamp = {2018.07.28},
}

@InProceedings{NB16,
  author    = {M. Neumann and J. Burgner-Kahrs},
  title     = {Considerations for follow-the-leader motion of extensible tendon-driven continuum robots},
  booktitle = {Proc. IEEE Int. Conf. Robotics and Automation (ICRA)},
  year      = {2016},
  pages     = {917--923},
  month     = may,
  doi       = {10.1109/ICRA.2016.7487223},
  keywords  = {manipulators, medical robotics, motion control, position control, 3D path, B-spline curves, continuum robots, extensible tendon-driven continuum robots, follow-the-leader motion, forward kinematics model, hyper-redundant snake robots, manipulator, minimally-invasive surgery, path following motion, Electron tubes, Kinematics, Manipulators, Robot kinematics, Surgery, Three-dimensional displays},
  owner     = {andi},
  timestamp = {2018.07.28},
}

@InProceedings{BKW13,
  author    = {Alan Bartow and Apoorva Kapadia and Ian D. Walker},
  title     = {A Novel Continuum Trunk Robot Based on Contractor Muscles},
  year      = {2013},
  owner     = {andi},
  timestamp = {2018.07.28},
}

@Article{SB98,
  author    = {R. S. Sutton and A. G. Barto},
  title     = {Reinforcement Learning: An Introduction},
  journal   = IEEE_J_NN,
  year      = {1998},
  volume    = {9},
  number    = {5},
  pages     = {1054},
  month     = sep,
  issn      = {1045-9227},
  doi       = {10.1109/TNN.1998.712192},
  keywords  = {Artificial intelligence, Artificial neural networks, Bibliographies, Books, Dynamic programming, Function approximation, Learning systems, Machine learning, Neural networks, Neurofeedback},
  owner     = {andi},
  timestamp = {2018.07.29},
}

@InProceedings{Moc01,
  author    = {H. Mochiyama},
  title     = {Whole-arm impedance of a serial-chain manipulator},
  booktitle = {Proc. ICRA. IEEE Int. Conf. Robotics and Automation (Cat. No.01CH37164)},
  year      = {2001},
  volume    = {3},
  pages     = {2223--2228 vol.3},
  month     = may,
  doi       = {10.1109/ROBOT.2001.932953},
  issn      = {1050-4729},
  keywords  = {manipulator kinematics, manipulator dynamics, whole-arm impedance, serial-chain manipulator, mechanical impedance, spatial curve, virtual reference, geometric task planning, whole-arm manipulation, Impedance, Shape control, Robots, Kinematics, Humans, Manipulator dynamics, Mechanical systems, Systems engineering and theory, Control theory, Hardware},
  owner     = {andi},
  timestamp = {2018.08.06},
}

@Misc{TFCL16,
  author    = {Thomas George Thuruthel and Egidio Falotico and Matteo Cianchetti and Cecilia Laschi},
  title     = {Learning Global Inverse Kinematics Solutions for a Continuum Robot},
  year      = {2016},
  doi       = {10.1007/978-3-319-33714-2_6},
  issn      = {0254-1971},
  owner     = {andi},
  pages     = {47-54},
  timestamp = {2018.08.06},
}

@Book{Murray:1994:MIR:561828,
  title     = {A Mathematical Introduction to Robotic Manipulation},
  publisher = {CRC Press, Inc.},
  year      = {1994},
  author    = {Murray, Richard M. and Sastry, S. Shankar and Zexiang, Li},
  address   = {Boca Raton, FL, USA},
  edition   = {1st},
  isbn      = {0849379814},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: keypattern_article:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_book:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_booklet:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_conference:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_electronic:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_ieeetranbstctl:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_inbook:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_incollection:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_inproceedings:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_manual:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_mastersthesis:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_misc:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_patent:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_periodical:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_phdthesis:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_proceedings:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_standard:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypattern_techreport:[authorsAlpha][shortyear];}

@Comment{jabref-meta: keypatterndefault:[authorsAlpha][shortyear];}
